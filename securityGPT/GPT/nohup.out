Using device: cuda
14.335553 M parameters
step 0: train loss 4.1866, val loss 4.1845
step 10: train loss 3.3457, val loss 3.3894
step 20: train loss 3.3104, val loss 3.3520
step 30: train loss 3.2788, val loss 3.3178
step 40: train loss 3.1221, val loss 3.1657
step 50: train loss 2.8865, val loss 2.9088
step 60: train loss 2.7095, val loss 2.7202
step 70: train loss 2.6294, val loss 2.6333
step 80: train loss 2.5819, val loss 2.5772
step 90: train loss 2.5546, val loss 2.5510
step 100: train loss 2.5361, val loss 2.5421
step 110: train loss 2.5214, val loss 2.5257
step 120: train loss 2.5077, val loss 2.5095
step 130: train loss 2.5004, val loss 2.5039
step 140: train loss 2.4860, val loss 2.4940
step 150: train loss 2.4826, val loss 2.4914
step 160: train loss 2.4726, val loss 2.4864
step 170: train loss 2.4692, val loss 2.4778
step 180: train loss 2.4645, val loss 2.4788
step 190: train loss 2.4486, val loss 2.4640
step 200: train loss 2.4420, val loss 2.4597
step 210: train loss 2.4342, val loss 2.4508
step 220: train loss 2.4215, val loss 2.4431
step 230: train loss 2.4238, val loss 2.4432
step 240: train loss 2.4055, val loss 2.4393
step 250: train loss 2.3949, val loss 2.4197
step 260: train loss 2.3782, val loss 2.4110
step 270: train loss 2.3558, val loss 2.3885
step 280: train loss 2.3532, val loss 2.3926
step 290: train loss 2.3344, val loss 2.3664
step 300: train loss 2.3161, val loss 2.3510
step 310: train loss 2.2864, val loss 2.3339
step 320: train loss 2.2626, val loss 2.3118
step 330: train loss 2.2568, val loss 2.3067
step 340: train loss 2.2203, val loss 2.2771
step 350: train loss 2.2091, val loss 2.2591
step 360: train loss 2.1840, val loss 2.2414
step 370: train loss 2.1587, val loss 2.2129
step 380: train loss 2.1417, val loss 2.1995
step 390: train loss 2.1086, val loss 2.1755
step 400: train loss 2.0913, val loss 2.1614
step 410: train loss 2.0719, val loss 2.1420
step 420: train loss 2.0481, val loss 2.1302
step 430: train loss 2.0303, val loss 2.1120
step 440: train loss 2.0090, val loss 2.0970
step 450: train loss 1.9781, val loss 2.0827
step 460: train loss 1.9549, val loss 2.0535
step 470: train loss 1.9330, val loss 2.0371
step 480: train loss 1.9096, val loss 2.0215
step 490: train loss 1.8884, val loss 2.0085
step 500: train loss 1.8786, val loss 2.0102
step 510: train loss 1.8523, val loss 1.9698
step 520: train loss 1.8297, val loss 1.9530
step 530: train loss 1.8063, val loss 1.9407
step 540: train loss 1.7951, val loss 1.9273
step 550: train loss 1.7722, val loss 1.9153
step 560: train loss 1.7653, val loss 1.9054
step 570: train loss 1.7449, val loss 1.8849
step 580: train loss 1.7401, val loss 1.8826
step 590: train loss 1.7176, val loss 1.8654
step 600: train loss 1.7035, val loss 1.8599
step 610: train loss 1.6934, val loss 1.8479
step 620: train loss 1.6797, val loss 1.8290
step 630: train loss 1.6680, val loss 1.8247
step 640: train loss 1.6553, val loss 1.8170
step 650: train loss 1.6475, val loss 1.8108
step 660: train loss 1.6422, val loss 1.8079
step 670: train loss 1.6187, val loss 1.7816
step 680: train loss 1.6159, val loss 1.7799
step 690: train loss 1.6078, val loss 1.7836
step 700: train loss 1.6007, val loss 1.7647
step 710: train loss 1.5863, val loss 1.7508
step 720: train loss 1.5860, val loss 1.7448
step 730: train loss 1.5700, val loss 1.7477
step 740: train loss 1.5640, val loss 1.7350
step 750: train loss 1.5550, val loss 1.7304
step 760: train loss 1.5535, val loss 1.7336
step 770: train loss 1.5488, val loss 1.7349
step 780: train loss 1.5361, val loss 1.7231
step 790: train loss 1.5211, val loss 1.7084
step 800: train loss 1.5229, val loss 1.7028
step 810: train loss 1.5186, val loss 1.7051
step 820: train loss 1.5022, val loss 1.6870
step 830: train loss 1.4993, val loss 1.6981
step 840: train loss 1.4934, val loss 1.6871
step 850: train loss 1.4951, val loss 1.6924
step 860: train loss 1.4797, val loss 1.6825
step 870: train loss 1.4729, val loss 1.6741
step 880: train loss 1.4721, val loss 1.6735
step 890: train loss 1.4605, val loss 1.6730
step 900: train loss 1.4636, val loss 1.6689
step 910: train loss 1.4577, val loss 1.6672
step 920: train loss 1.4474, val loss 1.6508
step 930: train loss 1.4418, val loss 1.6523
step 940: train loss 1.4408, val loss 1.6521
step 950: train loss 1.4398, val loss 1.6532
step 960: train loss 1.4360, val loss 1.6457
step 970: train loss 1.4241, val loss 1.6378
step 980: train loss 1.4241, val loss 1.6252
step 990: train loss 1.4133, val loss 1.6293
step 1000: train loss 1.4098, val loss 1.6221
step 1010: train loss 1.4072, val loss 1.6185
step 1020: train loss 1.4054, val loss 1.6139
step 1030: train loss 1.4037, val loss 1.6120
step 1040: train loss 1.3947, val loss 1.6128
step 1050: train loss 1.3955, val loss 1.6158
step 1060: train loss 1.3941, val loss 1.6110
step 1070: train loss 1.3856, val loss 1.6058
step 1080: train loss 1.3825, val loss 1.5999
step 1090: train loss 1.3771, val loss 1.5991
step 1100: train loss 1.3703, val loss 1.5940
step 1110: train loss 1.3650, val loss 1.5875
step 1120: train loss 1.3697, val loss 1.5936
step 1130: train loss 1.3650, val loss 1.5883
step 1140: train loss 1.3607, val loss 1.5895
step 1150: train loss 1.3597, val loss 1.5888
step 1160: train loss 1.3609, val loss 1.5969
step 1170: train loss 1.3477, val loss 1.5769
step 1180: train loss 1.3497, val loss 1.5807
step 1190: train loss 1.3423, val loss 1.5724
step 1200: train loss 1.3418, val loss 1.5666
step 1210: train loss 1.3358, val loss 1.5651
step 1220: train loss 1.3388, val loss 1.5698
step 1230: train loss 1.3314, val loss 1.5728
step 1240: train loss 1.3320, val loss 1.5687
step 1250: train loss 1.3262, val loss 1.5676
step 1260: train loss 1.3249, val loss 1.5687
step 1270: train loss 1.3195, val loss 1.5529
step 1280: train loss 1.3131, val loss 1.5506
step 1290: train loss 1.3145, val loss 1.5611
step 1300: train loss 1.3087, val loss 1.5404
step 1310: train loss 1.3100, val loss 1.5511
step 1320: train loss 1.3116, val loss 1.5502
step 1330: train loss 1.3063, val loss 1.5518
step 1340: train loss 1.3011, val loss 1.5543
step 1350: train loss 1.3005, val loss 1.5529
step 1360: train loss 1.2938, val loss 1.5454
step 1370: train loss 1.2930, val loss 1.5495
step 1380: train loss 1.2918, val loss 1.5440
step 1390: train loss 1.2898, val loss 1.5399
step 1400: train loss 1.2844, val loss 1.5310
step 1410: train loss 1.2822, val loss 1.5359
step 1420: train loss 1.2816, val loss 1.5411
step 1430: train loss 1.2821, val loss 1.5443
step 1440: train loss 1.2768, val loss 1.5352
step 1450: train loss 1.2751, val loss 1.5335
step 1460: train loss 1.2709, val loss 1.5316
step 1470: train loss 1.2721, val loss 1.5342
step 1480: train loss 1.2696, val loss 1.5311
step 1490: train loss 1.2724, val loss 1.5411
step 1500: train loss 1.2599, val loss 1.5215
step 1510: train loss 1.2634, val loss 1.5261
step 1520: train loss 1.2576, val loss 1.5263
step 1530: train loss 1.2611, val loss 1.5310
step 1540: train loss 1.2511, val loss 1.5120
step 1550: train loss 1.2549, val loss 1.5229
step 1560: train loss 1.2554, val loss 1.5224
step 1570: train loss 1.2450, val loss 1.5178
step 1580: train loss 1.2525, val loss 1.5198
step 1590: train loss 1.2464, val loss 1.5179
step 1600: train loss 1.2492, val loss 1.5229
step 1610: train loss 1.2411, val loss 1.5162
step 1620: train loss 1.2407, val loss 1.5149
step 1630: train loss 1.2335, val loss 1.5035
step 1640: train loss 1.2313, val loss 1.5129
step 1650: train loss 1.2374, val loss 1.5194
step 1660: train loss 1.2325, val loss 1.5084
step 1670: train loss 1.2310, val loss 1.5202
step 1680: train loss 1.2360, val loss 1.5263
step 1690: train loss 1.2276, val loss 1.5092
step 1700: train loss 1.2228, val loss 1.4990
step 1710: train loss 1.2263, val loss 1.5182
step 1720: train loss 1.2190, val loss 1.5147
step 1730: train loss 1.2193, val loss 1.5089
step 1740: train loss 1.2181, val loss 1.5105
step 1750: train loss 1.2173, val loss 1.4992
step 1760: train loss 1.2161, val loss 1.5083
step 1770: train loss 1.2106, val loss 1.5053
step 1780: train loss 1.2091, val loss 1.5037
step 1790: train loss 1.2076, val loss 1.4968
step 1800: train loss 1.2041, val loss 1.5008
step 1810: train loss 1.2086, val loss 1.5083
step 1820: train loss 1.2002, val loss 1.4953
step 1830: train loss 1.2004, val loss 1.5091
step 1840: train loss 1.1994, val loss 1.5017
step 1850: train loss 1.1986, val loss 1.5015
step 1860: train loss 1.1968, val loss 1.4996
step 1870: train loss 1.1900, val loss 1.4986
step 1880: train loss 1.1910, val loss 1.4926
step 1890: train loss 1.1930, val loss 1.5021
step 1900: train loss 1.1907, val loss 1.5033
step 1910: train loss 1.1860, val loss 1.4937
step 1920: train loss 1.1868, val loss 1.4999
step 1930: train loss 1.1922, val loss 1.5099
step 1940: train loss 1.1849, val loss 1.4939
step 1950: train loss 1.1818, val loss 1.5014
step 1960: train loss 1.1779, val loss 1.4914
step 1970: train loss 1.1780, val loss 1.4962
step 1980: train loss 1.1742, val loss 1.4919
step 1990: train loss 1.1751, val loss 1.4966
step 1999: train loss 1.1758, val loss 1.4952
Model saved to ../../models/gpt/2023-10-29_17-58-46_GPT.pth
Traceback (most recent call last):
  File "/home/alexy/Documents/SecurityGPT/securityGPT/GPT/model_test.py", line 258, in <module>
    print(decode(model.generate(context, max_new_tokens=1000)[0].tolist()))
  File "/home/alexy/Documents/SecurityGPT/securityGPT/GPT/model_test.py", line 199, in generate
    logits, loss = self(idx_cond)
  File "/home/alexy/Documents/SecurityGPT/env/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/alexy/Documents/SecurityGPT/env/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
TypeError: forward() missing 1 required positional argument: 'targets'
